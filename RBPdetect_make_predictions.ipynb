{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eb34cb8",
   "metadata": {},
   "source": [
    "# Dual identification of novel phage receptor-binding proteins based on protein domains and machine learning\n",
    "\n",
    "# *Predict new sequences*\n",
    "\n",
    "This notebook, together with the 'RBPdetect_protein_embeddings' notebook can be used to make predictions for protein sequences based on our domain-based, machine-learning-based and/or combined approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c148d1d8",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "1. Prepare a FASTA file with the **protein** sequences you want to make predictions for.\n",
    "\n",
    "2. Download HMMER (http://hmmer.org), unzip its contents on your computer and locate this folder (e.g. '/Users/Sally/hmmer-3.3.1'). You can put this folder anywhere you want on your computer, as long as you know where it is.\n",
    "\n",
    "3. Install all the necessary Python packages (*Libraries* below, click the hyperlinks for more info): [Biopython](https://biopython.org/wiki/Download), [tqdm](https://github.com/tqdm/tqdm#latest-pypi-stable-release), [xgboost](https://xgboost.readthedocs.io/en/stable/install.html), [NumPy](https://numpy.org/install/), [Pandas](https://pandas.pydata.org/docs/getting_started/install.html) and [Matplotlib](https://matplotlib.org/stable/users/installing/index.html). Typically you can install these packages via conda or pip, as mentioned in the installation guides that are hyperlinked. Often, NumPy, Pandas and Matplotlib come preinstalled.\n",
    "\n",
    "4. Go to [Google Colab](http://colab.research.google.com/) or [Kaggle](https://www.kaggle.com) to compute the necessary protein language embeddings, see details in the enumeration below. After computing, save the computed embeddings from Kaggle or Google Colab locally on your computer.\n",
    "    - In Colab, go to File > Upload notebook and then choose the 'RBPdetect_protein_embeddings' notebook in this repository after having it saved on your computer. Then Connect to a runtime (upper right of the screen) and finally go to Runtime > Change runtime type > make sure a GPU is enabled.\n",
    "    - On the Kaggle platform, first sign in or make an account. Then click the 'Create' button on the left and start a new notebook. On the next screen, do File > Import notebook and upload the 'RBPdetect_protein_embeddings' notebook from this repository.\n",
    "\n",
    "5. Copy the FASTA file and computed embeddings to the data folder of this repository. In the data folder, the RBPdetect_XGBmodel.json and/or RBPdetect_phageRBPs.hmm and/or RBPdetect_XGBhmm.json should also be located.\n",
    "\n",
    "6. Fill in the necessary file names in the second code block below.\n",
    "\n",
    "7. (Optional) To verify if HMMER software is properly installed and functioning, you can run predictions with the *Domain-based approach* (first few code blocks below) with the *sequences.fasta* example file. This file contains 3 protein sequences that are should all be predicted as RBPs (i.e., true positives). If this is not the case, then HMMER is not functioning properly (for troubleshooting: try looking at the outputs of the Pfam database press step before making predictions -> do you see errors or anything unexpected?).\n",
    "\n",
    "8. Run all the code blocks sequentially to make predictions based on the domain-based approach and/or machine-learning-based approach and/or combined approach (see different headers below). You can run code blocks either by clicking on them and pressing the play button 'Execute' on the top of the screen, or pressing shift+enter.\n",
    "\n",
    "9. The resulting dataframe with predictions contains a row for each of the protein sequences that was submitted. A binary prediction (0/1) is made for each of the methods. A '0' indicates that the sequence is predicted not to be an RBP, while a '1' indicates that the sequence is predicted as an RBP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17823fc",
   "metadata": {},
   "source": [
    "### Libraries and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8efac261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from tqdm.notebook import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import RBPdetect_utils as rbpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "637d4a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfam_file = 'data/RBPdetect_phageRBPs.hmm'\n",
    "xgb_model_embeddings = 'data/RBPdetect_xgb_model.json'\n",
    "xgb_model_combined = 'data/RBPdetect_xgb_hmm.json'\n",
    "fasta_file = 'data/sequences.fasta'\n",
    "hmmer_path = ... # e.g. '/Users/Sally/hmmer-3.3.1'\n",
    "embeddings_file = ... # e.g. 'data/embeddings.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e06594c",
   "metadata": {},
   "source": [
    "### Domain-based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ee5c405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# press the .hmm file for further use\n",
    "output, err = rbpu.hmmpress_python(hmmer_path, pfam_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc27d334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define HMMs to be detected as RBP-related\n",
    "N_blocks = ['Phage_T7_tail', 'Tail_spike_N', 'Prophage_tail', 'BppU_N', 'Mtd_N', \n",
    "           'Head_binding', 'DUF3751', 'End_N_terminal', 'phage_tail_N', 'Prophage_tailD1', \n",
    "           'DUF2163', 'Phage_fiber_2', 'unknown_N0', 'unknown_N1', 'unknown_N2', 'unknown_N3', 'unknown_N4', \n",
    "            'unknown_N6', 'unknown_N10', 'unknown_N11', 'unknown_N12', 'unknown_N13', 'unknown_N17', 'unknown_N19', \n",
    "            'unknown_N23', 'unknown_N24', 'unknown_N26','unknown_N29', 'unknown_N36', 'unknown_N45', 'unknown_N48', \n",
    "            'unknown_N49', 'unknown_N53', 'unknown_N57', 'unknown_N60', 'unknown_N61', 'unknown_N65', 'unknown_N73', \n",
    "            'unknown_N82', 'unknown_N83', 'unknown_N101', 'unknown_N114', 'unknown_N119', 'unknown_N122', \n",
    "            'unknown_N163', 'unknown_N174', 'unknown_N192', 'unknown_N200', 'unknown_N206', 'unknown_N208']\n",
    "C_blocks = ['Lipase_GDSL_2', 'Pectate_lyase_3', 'gp37_C', 'Beta_helix', 'Gp58', 'End_beta_propel', \n",
    "            'End_tail_spike', 'End_beta_barrel', 'PhageP22-tail', 'Phage_spike_2', \n",
    "            'gp12-short_mid', 'Collar', \n",
    "            'unknown_C2', 'unknown_C3', 'unknown_C8', 'unknown_C15', 'unknown_C35', 'unknown_C54', 'unknown_C76', \n",
    "            'unknown_C100', 'unknown_C105', 'unknown_C112', 'unknown_C123', 'unknown_C179', 'unknown_C201', \n",
    "            'unknown_C203', 'unknown_C228', 'unknown_C234', 'unknown_C242', 'unknown_C258', 'unknown_C262', \n",
    "            'unknown_C267', 'unknown_C268', 'unknown_C274', 'unknown_C286', 'unknown_C292', 'unknown_C294', \n",
    "            'Peptidase_S74', 'Phage_fiber_C', 'S_tail_recep_bd', 'CBM_4_9', 'DUF1983', 'DUF3672']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8182c497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ceae57e82764d0c991eb5671595d09a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scanning the proteins:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do domain-based detections\n",
    "domain_based_detections = rbpu.RBPdetect_domains_protein(hmmer_path, pfam_file, fasta_file, N_blocks=N_blocks, \n",
    "                                                         C_blocks=C_blocks, detect_others=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2edae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the domain-based detections\n",
    "domain_based_detections.to_csv('domains_based_detections.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351a3d1e",
   "metadata": {},
   "source": [
    "### Machine-learning-based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0fa40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load protein embeddings to make predictions for\n",
    "embeddings_df = pd.read_csv(embeddings_file)\n",
    "embeddings = np.asarray(embeddings_df.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de854b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained model\n",
    "xgb_saved = XGBClassifier()\n",
    "xgb_saved.load_model(xgb_model_embeddings)\n",
    "\n",
    "# make predictions with the XGBoost model\n",
    "score_xgb = xgb_saved.predict_proba(embeddings)[:,1]\n",
    "preds_xgb = (score_xgb > 0.5)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c97326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the embeddings-based predictions and scores\n",
    "xgb_results = pd.concat([pd.DataFrame(preds_xgb, columns=['preds']), \n",
    "                        pd.DataFrame(score_xgb, columns=['score'])], axis=1)\n",
    "xgb_results.to_csv('xgb_based_detections.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b9c266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions of both methods together (optional)\n",
    "names = [record.id for record in SeqIO.parse(fasta_file, 'fasta')]\n",
    "domain_preds = []\n",
    "for pid in names:\n",
    "    if pid in list(domain_based_detections['identifier']):\n",
    "        domain_preds.append(1)\n",
    "    else:\n",
    "        domain_preds.append(0)\n",
    "\n",
    "results = pd.DataFrame({'domain_based_predictions':domain_preds, 'machine_learning_predictions':preds_xgb})\n",
    "results.to_csv('detection_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39b0487",
   "metadata": {},
   "source": [
    "### Combined approach XGBoost + HMM scores\n",
    "\n",
    "Here, we combine both the embeddings of the proteins and the scores of each protein against all of the collected HMMs. These two types of features are concatenated and finally predictions are made (N.B. as a result, here predictions are made with a different XGBoost model than before)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13eb81b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define all the blocks we want scores for\n",
    "new_blocks = ['Phage_T7_tail', 'Tail_spike_N', 'Prophage_tail', 'BppU_N', 'Mtd_N', \n",
    "           'Head_binding', 'DUF3751', 'End_N_terminal', 'phage_tail_N', 'Prophage_tailD1', \n",
    "           'DUF2163', 'Phage_fiber_2', 'unknown_N0', 'unknown_N1', 'unknown_N2', 'unknown_N3', 'unknown_N4', \n",
    "            'unknown_N6', 'unknown_N10', 'unknown_N11', 'unknown_N12', 'unknown_N13', 'unknown_N17', 'unknown_N19', \n",
    "            'unknown_N23', 'unknown_N24', 'unknown_N26','unknown_N29', 'unknown_N36', 'unknown_N45', 'unknown_N48', \n",
    "            'unknown_N49', 'unknown_N53', 'unknown_N57', 'unknown_N60', 'unknown_N61', 'unknown_N65', 'unknown_N73', \n",
    "            'unknown_N82', 'unknown_N83', 'unknown_N101', 'unknown_N114', 'unknown_N119', 'unknown_N122', \n",
    "            'unknown_N163', 'unknown_N174', 'unknown_N192', 'unknown_N200', 'unknown_N206', 'unknown_N208', \n",
    "            'Lipase_GDSL_2', 'Pectate_lyase_3', 'gp37_C', 'Beta_helix', 'Gp58', 'End_beta_propel', \n",
    "            'End_tail_spike', 'End_beta_barrel', 'PhageP22-tail', 'Phage_spike_2', \n",
    "            'gp12-short_mid', 'Collar', \n",
    "            'unknown_C2', 'unknown_C3', 'unknown_C8', 'unknown_C15', 'unknown_C35', 'unknown_C54', 'unknown_C76', \n",
    "            'unknown_C100', 'unknown_C105', 'unknown_C112', 'unknown_C123', 'unknown_C179', 'unknown_C201', \n",
    "            'unknown_C203', 'unknown_C228', 'unknown_C234', 'unknown_C242', 'unknown_C258', 'unknown_C262', \n",
    "            'unknown_C267', 'unknown_C268', 'unknown_C274', 'unknown_C286', 'unknown_C292', 'unknown_C294', \n",
    "            'Peptidase_S74', 'Phage_fiber_C', 'S_tail_recep_bd', 'CBM_4_9', 'DUF1983', 'DUF3672']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02385ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# press the .hmm file for further use\n",
    "output, err = rbpu.hmmpress_python(hmmer_path, pfam_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d8ae0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06a6f4fb8bb4048b8420b1e98dc0744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scanning the proteins:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get domains & scores\n",
    "sequences = [str(sequence.seq) for sequence in SeqIO.parse(fasta_file, 'fasta')]\n",
    "hmm_scores = {item:[0]*len(sequences) for item in new_blocks}\n",
    "bar = tqdm(total=len(sequences), desc='Scanning the proteins', position=0, leave=True)\n",
    "for i, sequence in enumerate(sequences):\n",
    "    hits, scores, biases, ranges = rbpu.hmmscan_python_from_string(hmmer_path, pfam_file, sequence)\n",
    "    for j, dom in enumerate(hits):\n",
    "        hmm_scores[dom][i] = scores[j]\n",
    "    bar.update(1)\n",
    "bar.close()\n",
    "hmm_scores_array = np.asarray(pd.DataFrame(hmm_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a94ff277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load protein embeddings to make predictions for and concat them with the HMM scores\n",
    "embeddings_df = pd.read_csv(embeddings_file)\n",
    "embeddings = np.asarray(embeddings_df.iloc[:, 1:])\n",
    "features = np.concatenate((embeddings, hmm_scores_array), axis=1)\n",
    "\n",
    "# load trained model\n",
    "xgb_saved = XGBClassifier()\n",
    "xgb_saved.load_model(xgb_model_combined)\n",
    "\n",
    "# make predictions with the XGBoost model\n",
    "score_xgb = xgb_saved.predict_proba(features)[:,1]\n",
    "preds_xgb = (score_xgb > 0.5)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb354f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions\n",
    "names = [record.id for record in SeqIO.parse(fasta_file, 'fasta')]\n",
    "sequences = [str(record.seq) for record in SeqIO.parse(fasta_file, 'fasta')]\n",
    "preds_xgb = ['RBP' if x == 1 else 'nonRBP' for x in preds_xgb]\n",
    "xgb_based_detections = pd.DataFrame({'name': names, 'ProteinSeq': sequences, 'scores': score_xgb, 'prediction': preds_xgb})\n",
    "xgb_based_detections.to_csv('xgb_combined_detections.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "cdf400e2b2cf645b2ec6a448fcb5b3c1b3d3d5834714944466c9c0370880fa51"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
